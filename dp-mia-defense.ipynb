{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from dataclass_csv import DataclassWriter\n",
    "from dataclasses import dataclass\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import Flatten\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Tanh\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Softmax\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms import ToTensor\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the CIFAR10 dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the dataset should be stored\n",
    "DATA_PATH = './data'\n",
    "\n",
    "# Number of classes in the dataset\n",
    "N_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm sharing the test set across the victim and shadow models. About how the rest of the training set should be split up..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of training data for victim model, rest is for adversary\n",
    "VICTIM_TRAIN_FRAC = 0.2\n",
    "\n",
    "# Fraction of adversarial training data per shadow model training\n",
    "SHADOW_TRAIN_FRAC = 0.2\n",
    "\n",
    "# Number of shadow models\n",
    "N_SHADOW_MODELS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About hyperparameters for training... Probably want the epochs and victim and shadow models to be the same? Well, not now that we're doing differential privacy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CIFAR_EPOCHS = 100\n",
    "N_ATTACK_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some configuration choices..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Synchronous CUDA ops only\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attack model will have two branches. Paper didn't talk about how they did this so I'm experimenting here... Sigmoid is allegedly good for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_model() -> Module:\n",
    "    return Sequential(\n",
    "        Linear(10, 128),\n",
    "        ReLU(),\n",
    "        Linear(128, 128),\n",
    "        ReLU(),\n",
    "        Linear(128, 1),\n",
    "        Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some nice generic visualization of training process. Works for all of victim, shadow, and attack models all (not my code!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(losses, accuracies):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    ax1.plot(losses)\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    \n",
    "    ax2.plot(accuracies)\n",
    "    ax2.set_title('Training Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to train and evaluate a victim or shadow model. Shoud epochs and learning rate be different for the shadow models? (mostly not my code!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traincifar10(loader, epochs):\n",
    "    model = cifar_model().to(device)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-7)\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Progress bar for training batches\n",
    "        progress_bar = tqdm(loader, desc=f'Epoch {epoch + 1}/{epochs}')\n",
    "        \n",
    "        for i, data in enumerate(progress_bar):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': running_loss / ( i + 1),\n",
    "                'acc': 100.0 * correct / total\n",
    "            })\n",
    "\n",
    "            del inputs, labels\n",
    "        \n",
    "        # Store epoch metrics\n",
    "        epoch_loss = running_loss / len(loader)\n",
    "        epoch_acc = 100.0 * correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        #model.eval()\n",
    "\n",
    "    return model.cpu(), train_losses, train_accuracies\n",
    "\n",
    "def evaluatecifar10(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predvecs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader, desc='Evaluating'):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            predvec = model(images)\n",
    "            predvecs.append(predvec)\n",
    "            _, predicted = torch.max(predvec.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to train and evaluate an attack model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainattack(dataloader):\n",
    "    model = attack_model().to(device)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    #criterion = CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-7)\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    for epoch in range(N_ATTACK_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Progress bar for training batches\n",
    "        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch + 1}/{N_ATTACK_EPOCHS}')\n",
    "        \n",
    "        for i, data in enumerate(progress_bar):\n",
    "            traindata, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Create fresh tensors\n",
    "            #traindata = traindata.clone().detach()\n",
    "            #labels = labels.clone().detach()\n",
    "\n",
    "            # I'm not really sure why this is necessary, but it is\n",
    "            # Output has shape (128, 1) but labels has (128,)\n",
    "            #labels = labels.view(-1, 1).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # outputs = model(traindata)\n",
    "            outputs = model(traindata).squeeze()\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predicted = (outputs >= 0.5).float()\n",
    "            #predicted = outputs.argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': running_loss / ( i + 1),\n",
    "                'acc': 100.0 * correct / total\n",
    "            })\n",
    "        \n",
    "        # Store epoch metrics\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        epoch_acc = 100.0 * correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "    return model.cpu(), train_losses, train_accuracies\n",
    "\n",
    "def evaluatecattack(model, dataloader):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    membershipconf = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader, desc='Evaluating'):\n",
    "            input, labels = data[0].to(device), data[1].to(device)\n",
    "            labels = labels.view(-1, 1).float()\n",
    "            istrain = model(input)\n",
    "            membershipconf.append(istrain)\n",
    "            predicted = (istrain > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    #return torch.cat(membershipconf)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the CIFAR10 training and test sets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cifar_dataset(victim_frac: float) -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    tr = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    train_set = CIFAR10(DATA_PATH, train=True, download=True, transform=tr)\n",
    "    test_set = CIFAR10(DATA_PATH, train=False, download=True, transform=tr)\n",
    "\n",
    "    victim_size = int(victim_frac * len(train_set))\n",
    "    splits = [victim_size, len(train_set) - victim_size]\n",
    "    victim_set, adversary_set = random_split(train_set, splits)\n",
    "\n",
    "    return victim_set, adversary_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a `Dataset` into two tensors representing the features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_tensors(dataset: Dataset) -> List[Tensor]:\n",
    "    loader = DataLoader(dataset, batch_size=len(dataset))\n",
    "    return next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU memory management..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_gpu(model: Module, features: Tensor) -> Tensor:\n",
    "    model = model.to(device)\n",
    "    features = features.to(device)\n",
    "    output = model(features)\n",
    "    del model, features\n",
    "    torch.cuda.empty_cache()\n",
    "    return output.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two disjoint subsets of equal size from the adversarial `dataset` for the purpose of training and testing a shadow model. Each dataset uses `frac` of the total data available to the adversary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disjoint_subsets(dataset: Dataset, frac: float) -> Tuple[Dataset, Dataset]:\n",
    "    dataset_size = len(dataset)\n",
    "    subset_size = int(dataset_size * frac)\n",
    "    indexes = np.random.choice(dataset_size, 2 * subset_size, replace=False)\n",
    "    midpoint = len(indexes) // 2\n",
    "    train_set = Subset(dataset, indexes[:midpoint])\n",
    "    test_set = Subset(dataset, indexes[midpoint:])\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate attack model data for training or testing by feeding the `dataset` through a victim or shadow `model`. The generated data will be the model's confidence vector. The `label` should be 1 if the model was trained on the dataset and 0 if it was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_data(model: Module, dataset: Dataset, label: int) -> Dataset:\n",
    "    confidences = []\n",
    "    with torch.no_grad():\n",
    "        for batch in DataLoader(dataset, batch_size=64):\n",
    "            images, _ = batch[0], batch[1]\n",
    "            confidences.append(run_on_gpu(model, images))\n",
    "\n",
    "    _, cifar_labels = dataset_to_tensors(dataset)\n",
    "    attack_labels = torch.full([len(dataset)], label)\n",
    "    confidences = torch.cat(confidences)\n",
    "    return TensorDataset(confidences, cifar_labels, attack_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate balanced attack model training or testing data from two..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_attack_data(model: Module, train_set: Dataset, test_set: Dataset) -> Dataset:\n",
    "    train_attack = attack_data(model, train_set, 1)\n",
    "    test_attack = attack_data(model, test_set, 0)\n",
    "    return ConcatDataset([train_attack, test_attack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate attack model training data from a shadow model trained on `frac` of the adversarial `dataset`. The dataset will include the shadow model's confidence vectors for all the data it was trained on, and an equal number of confidence vectors for other adversarial data it was _not_ trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shadow_attack_data(n_shadows: int, dataset: Dataset, frac: float) -> Dataset:\n",
    "    attack_datasets = []\n",
    "    for _ in range(n_shadows):\n",
    "        train_set, test_set = disjoint_subsets(dataset, frac)\n",
    "        model = train_cifar_model(train_set, test_set)\n",
    "        attack_datasets.append(balanced_attack_data(model, train_set, test_set))\n",
    "    return ConcatDataset(attack_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate attack model testing data from a victim model. The dataset will include the victim model's confidence vectors on all its testing data, and an equal number of confidence vectors randomly selected from its training vector. This ensures it will be _balanced_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def victim_attack_data(model: Module, train_set: Dataset, test_set: Dataset) -> Dataset:\n",
    "    indexes = np.random.choice(len(train_set), len(test_set), replace=False)\n",
    "    train_subset = Subset(train_set, indexes)\n",
    "    return balanced_attack_data(model, train_subset, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model for CIFAR-10. The model is based..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_model() -> Module:\n",
    "    return Sequential(\n",
    "        Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "        Tanh(),\n",
    "        MaxPool2d(kernel_size=2, stride=2),\n",
    "        Conv2d(16, 16, kernel_size=3),\n",
    "        Tanh(),\n",
    "        MaxPool2d(kernel_size=2, stride=2),\n",
    "        Flatten(),\n",
    "        Linear(784, N_CLASSES),\n",
    "        Tanh(),\n",
    "        Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_victim_model(dataset: Dataset, batch_size: int, epsilon: float, delta: float, max_grad_norm: float) -> Module:\n",
    "    model = cifar_model().to(device)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-7)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    for epoch in range(N_CIFAR_EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Progress bar for training batches\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{N_CIFAR_EPOCHS}')\n",
    "        \n",
    "        for i, data in enumerate(progress_bar):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': running_loss / ( i + 1),\n",
    "                'acc': 100.0 * correct / total\n",
    "            })\n",
    "\n",
    "            del inputs, labels\n",
    "        \n",
    "        # Store epoch metrics\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100.0 * correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "\n",
    "    return model.cpu(), train_losses, train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar_model(train_set: Dataset, test_set: Dataset) -> Module:\n",
    "    loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "    model, asdf1, asdf2 = traincifar10(loader, N_CIFAR_EPOCHS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_model(train_set: Dataset) -> Module:\n",
    "    loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "    model, asdf1, asdf2 = trainattack(loader)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_cifar_label(dataset: Dataset, label: int) -> Dataset:\n",
    "    confidences, cifar_labels, attack_labels = dataset_to_tensors(dataset)\n",
    "    filtered_confidences = confidences[cifar_labels == label]\n",
    "    filtered_attack_labels = attack_labels[cifar_labels == label]\n",
    "    return TensorDataset(filtered_confidences, filtered_attack_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attack_models(n_labels: int, dataset: Dataset) -> List[Module]:\n",
    "    models = []\n",
    "    for label in range(n_labels):\n",
    "        filtered_dataset = filter_by_cifar_label(dataset, label)\n",
    "        model = train_attack_model(filtered_dataset)\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_set, adversary_set, test_set = split_cifar_dataset(VICTIM_TRAIN_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_model = train_cifar_model(victim_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_test_set = victim_attack_data(victim_model, victim_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_attack_train_set = shadow_attack_data(N_SHADOW_MODELS, adversary_set, SHADOW_TRAIN_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_models = train_attack_models(N_CLASSES, complete_attack_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(range(N_CLASSES))\n",
    "\n",
    "for label in labels:\n",
    "    filtered_dataset = filter_by_cifar_label(attack_test_set, label)\n",
    "    model = attack_models[label]\n",
    "    confidences = evaluatecattack(model, filtered_dataset)\n",
    "    #_, attacktestpreds = torch.max(confidences, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an experimenter, I don't care too much about testing the attack model on a dataset other than what I get from the victim model. As an attacker, I might care though: I won't know if my membership inference predictions against the victim model are right, and I might want to know when I deploy my attack model against the victim, how likely is it that they are. Generating test data from the victim model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 experiments\n"
     ]
    }
   ],
   "source": [
    "epsilons = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
    "deltas = [0.00001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "max_grad_norms = [0.1, 2.0, 10.0]\n",
    "\n",
    "param_combos = list(product(epsilons, deltas, batch_sizes, max_grad_norms))\n",
    "print(f'{len(param_combos)} experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0 hours\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(param_combos) * 10 / 60} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Experiment:\n",
    "    epsilon: float\n",
    "    delta: float\n",
    "    batch_size: int\n",
    "    max_grad_norm: float\n",
    "    cifar_label: int\n",
    "    victim_accuracy: float\n",
    "    attack_accuracy: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for epsilon, delta, batch_size, max_grad_norm in param_combos:\n",
    "    victim_model = train_cifar_model(victim_set, test_set) # TODO Make it private! Add hyperparams!\n",
    "    for label in labels:\n",
    "        filtered_dataset = filter_by_cifar_label(attack_test_set, label)\n",
    "        model = attack_models[label]\n",
    "        results.append(Experiment(\n",
    "            epsilon=epsilon,\n",
    "            delta=delta,\n",
    "            batch_size=batch_size,\n",
    "            max_grad_norm=max_grad_norm,\n",
    "            cifar_label=label,\n",
    "            victim_accuracy=evaluatecifar10(victim_model, test_set),\n",
    "            attack_accuracy=evaluatecattack(model, filtered_dataset)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dp-grid.csv', 'w') as file:\n",
    "    DataclassWriter(file, results, Experiment).write()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adversarial-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
